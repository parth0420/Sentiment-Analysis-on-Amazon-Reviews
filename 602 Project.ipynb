{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 602 Project\n",
    "For the project you will perform sentiment analysis on reviews from amazon.  The data to use is located here: http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Cell_Phones_and_Accessories_5.json.gz\n",
    "Note it is a gziped json file.  If you'd like to download and extract it directly into colab, this can be done using the following lines:\n",
    "!curl http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Cell_Phones_and_Accessories_5.json.gz -o reviews.json.gz\n",
    "!gunzip reviews.json.gz\n",
    "To view the file:\n",
    "!ls\n",
    "\n",
    "At this point it should be easily ingested into a pandas data frame. A few relevant fields are reviewText: The text from the review\n",
    "summary: The summary text from the review\n",
    "overall: The score the reviewer gave the item.\n",
    "\n",
    "\n",
    "Your task: \n",
    "Perform the necessary transformations to train both regression and classification models to predict the 'overall' field in the data set. This should include creating the correctly sized training and test sets.\n",
    "\n",
    "When performing the classification task, use overall less than 3 as negative, greater than 3 as positive, and 3 as neutral. If you'd prefer a numeric value 0 should be negative, 1 neutral and 2 positive.\n",
    "\n",
    "You may wish to drop the columns image, style and votes.  You may also wish the drop duplicate data.\n",
    "\n",
    "There are several options for using the summary and reviewText together, such as concatenating the strings, training separate models on both and feeding those results into another models, etc.  You may find that you don't want to use all fields (other that the ones I suggested dropping). I will let you experiment with this, just explain what you did and why.\n",
    "\n",
    "You should certainly apply vectorization and perhaps a pca or nmf as well.  Try at least three different classifiers/regressors.  Attempt to get the best possible result, remember the different metrics we discussed for evaluating models.  Discuss which metric you this you should optimize for and why.  Pipelines and grid search will certainly help in optimizing your results!\n",
    "\n",
    "Write a 5 page or less paper describing your work and the performance you were able to achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install  gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from datetime import *\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize \n",
    "import io \n",
    "from nltk.corpus import stopwords \n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Cell_Phones_and_Accessories_5.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json( file , lines= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>08 4, 2014</td>\n",
       "      <td>A24E3SXTC62LJI</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>{'Color:': ' Bling'}</td>\n",
       "      <td>Claudia Valdivia</td>\n",
       "      <td>Looks even better in person. Be careful to not...</td>\n",
       "      <td>Can't stop won't stop looking at it</td>\n",
       "      <td>1407110400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 12, 2014</td>\n",
       "      <td>A269FLZCB4GIPV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sarah ponce</td>\n",
       "      <td>When you don't want to spend a whole lot of ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>1392163200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2014</td>\n",
       "      <td>AB6CHQWHZW4TV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kai</td>\n",
       "      <td>so the case came on time, i love the design. I...</td>\n",
       "      <td>Its okay</td>\n",
       "      <td>1391817600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>02 4, 2014</td>\n",
       "      <td>A1M117A53LEI8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sharon Williams</td>\n",
       "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...</td>\n",
       "      <td>CASE</td>\n",
       "      <td>1391472000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>02 3, 2014</td>\n",
       "      <td>A272DUT8M88ZS8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bella Rodriguez</td>\n",
       "      <td>I liked it because it was cute, but the studs ...</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1391385600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True   08 4, 2014  A24E3SXTC62LJI  7508492919   \n",
       "1        5      True  02 12, 2014  A269FLZCB4GIPV  7508492919   \n",
       "2        3      True   02 8, 2014   AB6CHQWHZW4TV  7508492919   \n",
       "3        2      True   02 4, 2014   A1M117A53LEI8  7508492919   \n",
       "4        4      True   02 3, 2014  A272DUT8M88ZS8  7508492919   \n",
       "\n",
       "                  style      reviewerName  \\\n",
       "0  {'Color:': ' Bling'}  Claudia Valdivia   \n",
       "1                   NaN       sarah ponce   \n",
       "2                   NaN               Kai   \n",
       "3                   NaN   Sharon Williams   \n",
       "4                   NaN   Bella Rodriguez   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Looks even better in person. Be careful to not...   \n",
       "1  When you don't want to spend a whole lot of ca...   \n",
       "2  so the case came on time, i love the design. I...   \n",
       "3  DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...   \n",
       "4  I liked it because it was cute, but the studs ...   \n",
       "\n",
       "                               summary  unixReviewTime vote image  \n",
       "0  Can't stop won't stop looking at it      1407110400  NaN   NaN  \n",
       "1                                    1      1392163200  NaN   NaN  \n",
       "2                             Its okay      1391817600  NaN   NaN  \n",
       "3                                 CASE      1391472000  NaN   NaN  \n",
       "4                                Cute!      1391385600  NaN   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128437, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop( columns = [ 'image', 'style' , 'vote' ] , inplace=True )  #Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall             0\n",
       "verified            0\n",
       "reviewTime          0\n",
       "reviewerID          0\n",
       "asin                0\n",
       "reviewerName      135\n",
       "reviewText        765\n",
       "summary           517\n",
       "unixReviewTime      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # To check null values in Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3984"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()].shape[0]        #Checking Duplicate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.123089e+06</td>\n",
       "      <td>1.123089e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.221692e+00</td>\n",
       "      <td>1.440653e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.231564e+00</td>\n",
       "      <td>4.525683e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.035331e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.416528e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.444435e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.470528e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.538438e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall  unixReviewTime\n",
       "count  1.123089e+06    1.123089e+06\n",
       "mean   4.221692e+00    1.440653e+09\n",
       "std    1.231564e+00    4.525683e+07\n",
       "min    1.000000e+00    1.035331e+09\n",
       "25%    4.000000e+00    1.416528e+09\n",
       "50%    5.000000e+00    1.444435e+09\n",
       "75%    5.000000e+00    1.470528e+09\n",
       "max    5.000000e+00    1.538438e+09"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewTime'] = df['reviewTime'].apply(lambda x: datetime.strptime(str(x),'%m %d, %Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-Processing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(line):          #Function to clean the text \n",
    "    filtered_words=[]\n",
    "    stop_words = set(stopwords.words('english'))     \n",
    "    \n",
    "    words = word_tokenize(line)                         #Splitting into words\n",
    "    words = [word.lower() for word in words]             # All words to lowercase\n",
    "    words = [word for word in words if word.isalpha()]   #only alphabets are taken (punct,digits etc removed)\n",
    "\n",
    "    for r in words: \n",
    "        if r not in stop_words:              # Removing stop words\n",
    "            filtered_words.append(r)         \n",
    "            \n",
    "    return filtered_words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ 'ReviewText' ] = df[ 'reviewText' ].str.cat( df[ 'summary' ] , sep=\" \" )  #  Concatenating reviewText and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop( columns = [ 'reviewText', 'summary'  ] , inplace=True )  #Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ReviewText'] = df['ReviewText'].apply(clean)    #Applying clean function to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(overall):      \n",
    "    op = 0\n",
    "    if overall == 3 :\n",
    "        op = 1\n",
    "    elif overall >= 3 :\n",
    "        op = 2\n",
    "    elif overall <= 3 :\n",
    "        op = 0\n",
    "        \n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']=df['overall'].apply(target)           # New target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['looks',\n",
       " 'even',\n",
       " 'better',\n",
       " 'person',\n",
       " 'careful',\n",
       " 'drop',\n",
       " 'phone',\n",
       " 'often',\n",
       " 'rhinestones',\n",
       " 'fall',\n",
       " 'duh',\n",
       " 'decorative',\n",
       " 'case',\n",
       " 'protective',\n",
       " 'say',\n",
       " 'fits',\n",
       " 'perfectly',\n",
       " 'securely',\n",
       " 'phone',\n",
       " 'overall',\n",
       " 'pleased',\n",
       " 'purchase',\n",
       " 'ca',\n",
       " 'stop',\n",
       " 'wo',\n",
       " 'stop',\n",
       " 'looking']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=df['ReviewText'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model=Word2Vec(review,min_count=5,size=50,workers=4)    #Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(rev):       #Vectorizing words in text\n",
    "    vectsum = []\n",
    "    for line in rev:\n",
    "        vectline = np.zeros(50)\n",
    "        num=0\n",
    "        for word in line: \n",
    "            if word in w2v_words:\n",
    "                vectline += w2v_model.wv[word]\n",
    "                num += 1\n",
    "        if num != 0:\n",
    "            vectline /= num\n",
    "        vectsum.append(vectline)\n",
    "    return vectsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewvectors']=vec(review) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>target</th>\n",
       "      <th>reviewvectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-08-04</td>\n",
       "      <td>A24E3SXTC62LJI</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>Claudia Valdivia</td>\n",
       "      <td>1407110400</td>\n",
       "      <td>[looks, even, better, person, careful, drop, p...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.9326032150398802, 0.27075807964084325, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-02-12</td>\n",
       "      <td>A269FLZCB4GIPV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>sarah ponce</td>\n",
       "      <td>1392163200</td>\n",
       "      <td>[want, spend, whole, lot, cash, want, great, d...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.631149485707283, -1.7938518196344375, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-02-08</td>\n",
       "      <td>AB6CHQWHZW4TV</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>Kai</td>\n",
       "      <td>1391817600</td>\n",
       "      <td>[case, came, time, love, design, actually, mis...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.29744592173533, 0.21961938657543875, 0.2175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-02-04</td>\n",
       "      <td>A1M117A53LEI8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>Sharon Williams</td>\n",
       "      <td>1391472000</td>\n",
       "      <td>[care, gave, gift, okay, expected, case]</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.04533412059148153, 1.3900722414255142, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>A272DUT8M88ZS8</td>\n",
       "      <td>7508492919</td>\n",
       "      <td>Bella Rodriguez</td>\n",
       "      <td>1391385600</td>\n",
       "      <td>[liked, cute, studs, fall, easily, protect, ph...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.403727525460104, 1.0023157136658063, -0.474...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified reviewTime      reviewerID        asin      reviewerName  \\\n",
       "0        5      True 2014-08-04  A24E3SXTC62LJI  7508492919  Claudia Valdivia   \n",
       "1        5      True 2014-02-12  A269FLZCB4GIPV  7508492919       sarah ponce   \n",
       "2        3      True 2014-02-08   AB6CHQWHZW4TV  7508492919               Kai   \n",
       "3        2      True 2014-02-04   A1M117A53LEI8  7508492919   Sharon Williams   \n",
       "4        4      True 2014-02-03  A272DUT8M88ZS8  7508492919   Bella Rodriguez   \n",
       "\n",
       "   unixReviewTime                                         ReviewText  target  \\\n",
       "0      1407110400  [looks, even, better, person, careful, drop, p...       2   \n",
       "1      1392163200  [want, spend, whole, lot, cash, want, great, d...       2   \n",
       "2      1391817600  [case, came, time, love, design, actually, mis...       1   \n",
       "3      1391472000           [care, gave, gift, okay, expected, case]       0   \n",
       "4      1391385600  [liked, cute, studs, fall, easily, protect, ph...       2   \n",
       "\n",
       "                                       reviewvectors  \n",
       "0  [0.9326032150398802, 0.27075807964084325, -0.0...  \n",
       "1  [-1.631149485707283, -1.7938518196344375, -0.8...  \n",
       "2  [1.29744592173533, 0.21961938657543875, 0.2175...  \n",
       "3  [-0.04533412059148153, 1.3900722414255142, -0....  \n",
       "4  [1.403727525460104, 1.0023157136658063, -0.474...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecdf = pd.DataFrame(df['reviewvectors'].tolist(), index= df.index)       #Vectors to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1123089, 50)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsne2d = TSNE( n_components=2,    init='random',     # PCA  takes long time\n",
    "    random_state=101,    method='barnes_hut',\n",
    "    n_iter=250,    verbose=2,\n",
    "    angle=0.5).fit_transform(vecdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(vecdf,df['target'], test_size=0.3)  #Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-w6sHI0yZeN"
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "param = {'max_depth':[5,10,15]}\n",
    "gs = GridSearchCV(tree,param)\n",
    "gs.fit(X_train,Y_train)\n",
    "bestgrid = gs.best_estimator_\n",
    "y_test = bestgrid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZy4zay-yab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters are {'max_depth': 10}\n",
      "Accuracy score =  0.838792972958534\n",
      "F1-score =  0.807390060488788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 21227,    605,  19601],\n",
       "       [  5414,   3003,  20912],\n",
       "       [  7247,    536, 258382]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Optimal parameters are\",gs.best_params_)\n",
    "print(\"Accuracy score = \",bestgrid.score(X_test,Y_test))\n",
    "print(\"F1-score = \",f1_score(Y_test,y_test,average='weighted'))\n",
    "print(\"Confusion Matrix :\",confusion_matrix(Y_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WpoeF4isOxs"
   },
   "outputs": [],
   "source": [
    "lrparam = {}\n",
    "lrparam['C'] = []\n",
    "for i in range(-3,3):\n",
    "    lrparam['C'].append(10 ** i)   # C value is 0.001,0.01,0.1,1,10,100\n",
    "    \n",
    "lr = LogisticRegression(class_weight='balanced', penalty='l2', random_state=2)\n",
    "    \n",
    "gs = GridSearchCV(lr,lrparam)\n",
    "gs.fit(X_train,Y_train)\n",
    "bestgrid = gs.best_estimator_\n",
    "y_test = bestgrid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "saE58ICYsPct",
    "outputId": "0e33069b-9358-4707-e86e-addf8cae01e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters =  {'C': 0.01}\n",
      "Accuracy score =  0.8410130384326575\n",
      "F1-score =  0.8424723385733639\n",
      "Confusion Matrix : [[ 30122   4677   6649]\n",
      " [  8080  10439  10696]\n",
      " [ 11492  11973 242799]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal parameters = \",gs.best_params_)\n",
    "print(\"Accuracy score = \",bestgrid.score(X_test,Y_test))\n",
    "print(\"F1-score = \",f1_score(Y_test,y_test,average='weighted'))\n",
    "print(\"Confusion Matrix :\",confusion_matrix(Y_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qsfmW1YRq3Gu"
   },
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nUQXS7DVq3Gv",
    "outputId": "9a59003b-1c2d-409a-c596-afe2ec6b0724"
   },
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(class_weight='balanced',penalty='l2',random_state=1)    \n",
    "gs = GridSearchCV(lsvc,lrparam)\n",
    "gs.fit(X_train,Y_train)\n",
    "bestgrid = gs.best_estimator_\n",
    "y_test = bestgrid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "lfLs-PB4q3Gy",
    "outputId": "cfd301ae-657a-4fdc-ebe5-046b2c2ecc96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters are {'C': 10}\n",
      "Accuracy score =  0.8449011210143443\n",
      "F1-score =  0.8354449858356258\n",
      "Confusion Matrix : [[ 30851   2497   8100]\n",
      " [ 10301   5969  12945]\n",
      " [ 12912   5502 247850]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal parameters are\",gs.best_params_)\n",
    "print(\"Accuracy score = \",bestgrid.score(X_test,Y_test))\n",
    "print(\"F1-score = \",f1_score(Y_test,y_test,average='weighted'))\n",
    "print(\"Confusion Matrix :\",confusion_matrix(Y_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLzQA7SDq3G1"
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyZ200h0q3G3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(vecdf,df['overall'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnFxZkVTq3G5"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "W3k0l6uBq3G6",
    "outputId": "49cfa21f-6bbb-469f-aa82-0bf2ebdb0fd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  72.37497308676487\n",
      "Coefficient of determination R2 score =  0.4629704230465106\n",
      "Mean square error=  0.814794408879482\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "r2_score = clf.score(X_test,Y_test)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "errors = abs(predictions - Y_test)\n",
    "m = 100 * np.mean(errors / Y_test)\n",
    "accuracy = 100 - m\n",
    "print(\"Accuracy = \",accuracy)\n",
    "print(\"Coefficient of determination R2 score = \",r2_score)\n",
    "print(\"Mean square error = \",mean_squared_error(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kjo9bmyWq3G8"
   },
   "source": [
    "# DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xJRLlRM4q3G8",
    "outputId": "dcadc20c-8f9b-4714-b1f0-012f56af2894"
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[4,5,6,7,8]}\n",
    "dt = DecisionTreeRegressor()\n",
    "gs = GridSearchCV(dt,parameters)\n",
    "gs.fit(X_train,Y_train)\n",
    "y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "f7iynrU_q3G_",
    "outputId": "71598e84-379d-42dc-d08f-783ae17cce62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters are {'max_depth': 8}\n",
      "Accuracy =  74.24650746684881\n",
      "Coefficient of determination R2 score =  0.4484922804136525\n",
      "Mean square error=  0.8367610009899834\n"
     ]
    }
   ],
   "source": [
    "bestgrid = gs.best_estimator_\n",
    "r2_score = bestgrid.score(X_test,Y_test)\n",
    "predictions = bestgrid.predict(X_test)\n",
    "errors = abs(predictions - Y_test)\n",
    "m = 100 * np.mean(errors / Y_test)\n",
    "accuracy = 100 - m\n",
    "print(\"Optimal parameters are\",gs.best_params_)\n",
    "print(\"Accuracy = \",accuracy)\n",
    "print(\"Coefficient of determination R2 score = \",r2_score)\n",
    "print(\"Mean square error= \",mean_squared_error(Y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
